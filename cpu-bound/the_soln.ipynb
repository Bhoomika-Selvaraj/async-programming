{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "390b9c7f",
   "metadata": {},
   "source": [
    "Before `ProcessPoolExecutor` let me tell abt `ThreadPoolExecutor`.\n",
    "\n",
    "Context: Running threads in the background with `loop.run_in_executor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9058f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "def cpu_heavy(n):\n",
    "    print(\"Starting heavy work\")\n",
    "    time.sleep(3)\n",
    "    print(\"Done heavy work\")\n",
    "    return n * n\n",
    "\n",
    "async def main():\n",
    "    loop = asyncio.get_running_loop()\n",
    "    result = await loop.run_in_executor(None, cpu_heavy, 10)\n",
    "    print(\"Result:\", result)\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f71d47c",
   "metadata": {},
   "source": [
    "What’s happening:\n",
    "\n",
    "1.  loop.run_in_executor(None, cpu_heavy, 10)\n",
    "→ Runs cpu_heavy(10) in a ThreadPoolExecutor (background thread).\n",
    "\n",
    "2.  The event loop doesn’t block, it can keep serving other coroutines.\n",
    "\n",
    "3.   await waits for the result, but meanwhile the event loop can switch to other tasks.\n",
    "\n",
    "\n",
    "By default, `None` means `ThreadPoolExecutor`(best for IO bound tasks). You can also use `ProcessPoolExecutor` for CPU-bound tasks.\n",
    "\n",
    "`ProcessPoolExecutor` -> Spin up a whole new python process in the background. It’s heavier than threads but bypasses the GIL, so it’s better for CPU-heavy work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81232756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "\n",
    "def cpu_heavy(n):\n",
    "    print(\"Starting heavy work\")\n",
    "    time.sleep(3)\n",
    "    print(\"Done heavy work\")\n",
    "    return n * n\n",
    "\n",
    "async def main():\n",
    "    loop = asyncio.get_running_loop()\n",
    "    with ProcessPoolExecutor() as pool:\n",
    "        result = await loop.run_in_executor(pool, cpu_heavy, 10) #Here None is replaced by 'pool'\n",
    "        print(result)\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a8454d",
   "metadata": {},
   "source": [
    "Wait!\n",
    "\n",
    "You might think: \n",
    "\"Why use ThreadPoolExecutor in the first place since async can handle IO bound tasks gracefully?Also only one thread can execute Python bytecode at a time.\n",
    "So if you have CPU-bound code (pure Python math loops, JSON parsing, etc.), multiple threads don’t run in parallel, the GIL serializes them??\"\n",
    "\n",
    "Who thinks this long, sry for the very long context😝 Okay, here we go!\n",
    "There are many libraries and APIs that are blocking and have no async version. For example **requests** (HTTP client), **sqlite3** (database), and standard file operations. These are blocking calls that would block the event loop if used directly in async code. That means even if 100 users hit the server, all are frozen until that blocking call finishes.\n",
    "\n",
    "> Intuition: Releasing the GIL alone doesn’t create concurrency.\n",
    "\n",
    "Legacy libraries like requests and sqlite3 are implemented in C and _**release the GIL**_ during blocking operations(If there are no other coroutines to run, releasing the GIL doesn’t help by itself!). This means that while one thread is waiting for a network response or disk I/O, other threads can run Python code.\n",
    "\n",
    "* Even though the GIL is released during the network wait, in a single-threaded program there’s nothing else to run.\n",
    "* The program is basically idle while waiting for the response.\n",
    "* So, releasing the GIL alone doesn’t magically give concurrency, we need other threads or coroutines to make use of that idle time.So using ThreadPoolExecutor with these blocking libraries can improve concurrency and throughput in an async application.\n",
    "\n",
    "**Qn**:'Why not use ThreadPoolExecutor instead of async then?'\n",
    "\n",
    "**Ans**: Async is generally more efficient than threads for I/O-bound tasks because it avoids the overhead of thread management and context switching. Async code can handle many concurrent operations with a single thread, while threads require more memory and CPU resources. So use async for I/O-bound tasks when possible, and use ThreadPoolExecutor for blocking libraries that don’t have async versions.\n",
    "\n",
    "\n",
    "```\n",
    "Single-thread + blocking I/O\n",
    "[requests.get()] --> idle (nothing else runs)\n",
    "\n",
    "ThreadPoolExecutor\n",
    "[Thread 1: requests.get()] --> GIL released\n",
    "[Thread 2: another request] --> runs while Thread 1 waits\n",
    "\n",
    "Async\n",
    "[Coroutine 1: await aiohttp] --> yields to event loop\n",
    "[Coroutine 2: await aiohttp] --> runs while Coroutine 1 waits\n",
    "All in single thread, very lightweight\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a05d40",
   "metadata": {},
   "source": [
    "| Work type                                       | Async (`await`) | ThreadPoolExecutor     | ProcessPoolExecutor |\n",
    "| ----------------------------------------------- | --------------- | ---------------------- | ------------------- |\n",
    "| Async I/O libs (httpx, aiohttp, asyncpg)        |  Best          |  Not needed           |  Not needed        |\n",
    "| Blocking I/O libs (requests, sqlite3, file ops) |  Blocks loop   |  Works well           |  Overkill         |\n",
    "| CPU-heavy (hashing, ML, image resize)           |  Blocks loop   |  GIL prevents speedup |  True parallel     |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
